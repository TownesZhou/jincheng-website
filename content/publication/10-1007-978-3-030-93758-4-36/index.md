---
# Documentation: https://wowchemy.com/docs/managing-content/

title: 'PySigma: Towards Enhanced Grand Unification for the Sigma Cognitive Architecture'
subtitle: ''
summary: ''
authors:
- Jincheng Zhou
- Volkan Ustun
tags: []
categories: []
date: '2022-01-01'
lastmod: 2022-01-07T23:30:17-08:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2022-01-08T07:30:07.043314Z'
publication_types:
- '1'
abstract: The Sigma cognitive architecture is the beginning of an integrated computational
  model of intelligent behavior aimed at the grand goal of artificial general intelligence
  (AGI). However, whereas it has been proven to be capable of modeling a wide range
  of intelligent behaviors, the existing implementation of Sigma has suffered from
  several significant limitations. The most prominent one is the inadequate support
  for inference and learning on continuous variables. In this article, we propose
  solutions for this limitation that should together enhance Sigma's level of grand
  unification; that is, its ability to span both traditional cognitive capabilities
  and key non-cognitive capabilities central to general intelligence, bridging the
  gap between symbolic, probabilistic, and neural processing. The resulting design
  changes converge on a more capable version of the architecture called PySigma. We
  demonstrate such capabilities of PySigma in neural probabilistic processing via
  deep generative models, specifically variational autoencoders, as a concrete example.
publication: '*Artificial General Intelligence*'
---
